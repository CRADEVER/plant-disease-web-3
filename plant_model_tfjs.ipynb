{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "# Configure TensorFlow\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Constants\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS_NEW = 15\n",
    "EPOCHS_FINE = 8\n",
    "BASE_DIR = '/content/drive/MyDrive'\n",
    "DATASET_PATH = f'{BASE_DIR}/dataset'\n",
    "MODEL_PATH = f'{BASE_DIR}/plant_model.keras'\n",
    "TFJS_PATH = f'{BASE_DIR}/plant_model_js'\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(TFJS_PATH, exist_ok=True)\n",
    "\n",
    "# Enhanced data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Data generators\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    DATASET_PATH,\n",
    "    target_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "num_classes = len(train_gen.class_indices)\n",
    "\n",
    "def build_model(num_classes):\n",
    "    # Initialize MobileNetV2 base\n",
    "    base = MobileNetV2(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMG_SIZE, IMG_SIZE, 3)\n",
    "    )\n",
    "    base.trainable = False\n",
    "\n",
    "    # Add custom layers\n",
    "    x = base.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create and compile model\n",
    "    model = Model(base.input, outputs)\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Load or create model\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    print(\"Loading existing model...\")\n",
    "    model = load_model(MODEL_PATH)\n",
    "    # Fine-tune last layers\n",
    "    for layer in model.layers[-30:]:\n",
    "        if not isinstance(layer, (Dropout, BatchNormalization)):\n",
    "            layer.trainable = True\n",
    "    epochs = EPOCHS_FINE\n",
    "else:\n",
    "    print(\"Creating new model...\")\n",
    "    model = build_model(num_classes)\n",
    "    epochs = EPOCHS_NEW\n",
    "\n",
    "# Enhanced callbacks\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        MODEL_PATH,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.2,\n",
    "        patience=3,\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    workers=4,\n",
    "    use_multiprocessing=True\n",
    ")\n",
    "\n",
    "# Save model and convert to TensorFlow.js format\n",
    "model.save(MODEL_PATH)\n",
    "print(f\"\\nSaving model to {MODEL_PATH}\")\n",
    "\n",
    "# Convert to TF.js format\n",
    "!rm -rf {TFJS_PATH}\n",
    "os.makedirs(TFJS_PATH, exist_ok=True)\n",
    "!tensorflowjs_converter --input_format=keras \\\n",
    "    --output_format=tfjs_layers_model \\\n",
    "    --quantize_uint8 \\\n",
    "    {MODEL_PATH} {TFJS_PATH}\n",
    "\n",
    "# Save class labels\n",
    "with open(os.path.join(TFJS_PATH, 'labels.js'), 'w') as f:\n",
    "    f.write(f\"const CLASS_NAMES = {list(train_gen.class_indices.keys())};\")\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\n‚úÖ Model saved to: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ TF.js model saved to: {TFJS_PATH}\")\n",
    "print(f\"üß† Trainable parameters: {sum(tf.keras.backend.count_params(w) for w in model.trainable_weights):,}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6xX1BQjndFfr"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install -q tensorflow tensorflowjs matplotlib\n",
    "import os, tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "BASE_DIR = '/content/drive/MyDrive'\n",
    "DATASET_PATH = f'{BASE_DIR}/dataset'\n",
    "MODEL_PATH   = f'{BASE_DIR}/plant_model.keras'\n",
    "TFJS_PATH    = f'{BASE_DIR}/plant_model_js'\n",
    "\n",
    "os.makedirs(TFJS_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y4U0uHlVdKEH"
   },
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE, BATCH, EPOCHS_NEW, EPOCHS_FINE = 224, 32, 10, 5\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    validation_split=0.2,\n",
    "    rotation_range=20, width_shift_range=0.1, height_shift_range=0.1,\n",
    "    zoom_range=0.2, horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(DATASET_PATH, target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                        batch_size=BATCH, class_mode='categorical',\n",
    "                                        subset='training', shuffle=True)\n",
    "val_gen = datagen.flow_from_directory(DATASET_PATH, target_size=(IMG_SIZE, IMG_SIZE),\n",
    "                                      batch_size=BATCH, class_mode='categorical',\n",
    "                                      subset='validation', shuffle=False)\n",
    "\n",
    "num_classes = len(train_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhkZa0TndP2n",
    "outputId": "bd01a9cb-bf8f-4f57-b44d-8a817a3db354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m658s\u001b[0m 3s/step - accuracy: 0.9993 - loss: 0.0035 - val_accuracy: 0.9969 - val_loss: 0.0082\n",
      "Epoch 2/5\n",
      "\u001b[1m240/240\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m586s\u001b[0m 2s/step - accuracy: 0.9987 - loss: 0.0036 - val_accuracy: 0.9963 - val_loss: 0.0140\n",
      "Epoch 3/5\n",
      "\u001b[1m 43/240\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m6:33\u001b[0m 2s/step - accuracy: 0.9975 - loss: 0.0066"
     ]
    }
   ],
   "source": [
    "def build_model(num_classes):\n",
    "    base = MobileNetV2(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    base.trainable = False\n",
    "    x = GlobalAveragePooling2D()(base.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    out = Dense(num_classes, activation='softmax')(x)\n",
    "    model = Model(base.input, out)\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if os.path.exists(MODEL_PATH):\n",
    "    model = load_model(MODEL_PATH)\n",
    "    for layer in model.layers[-20:]:\n",
    "        if not isinstance(layer, Dropout): layer.trainable = True\n",
    "    epochs = EPOCHS_FINE\n",
    "else:\n",
    "    model = build_model(num_classes)\n",
    "    epochs = EPOCHS_NEW\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(MODEL_PATH, save_best_only=True, monitor='val_accuracy', mode='max'),\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "]\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CfiZqbINWU24"
   },
   "outputs": [],
   "source": [
    "model.save(MODEL_PATH)\n",
    "!rm -rf {TFJS_PATH}\n",
    "os.makedirs(TFJS_PATH, exist_ok=True)\n",
    "!tensorflowjs_converter --input_format=keras --output_format=tfjs_layers_model {MODEL_PATH} {TFJS_PATH}\n",
    "with open(os.path.join(TFJS_PATH, 'labels.js'), 'w') as f:\n",
    "    f.write(f\"const CLASS_NAMES = {list(train_gen.class_indices.keys())};\")\n",
    "\n",
    "print(f\"‚úÖ MODEL: {MODEL_PATH}\")\n",
    "print(f\"‚úÖ TFJS:  {TFJS_PATH}\")\n",
    "print(f\"üß† Trainable params: {sum(tf.keras.backend.count_params(w) for w in model.trainable_weights):,}\")\n",
    "model.summary()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN+iC/NlQuR07A7AtbWDmTz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
